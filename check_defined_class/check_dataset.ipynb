{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid \n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/retinanet_')\n",
    "\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer,CSVDataset\n",
    "from config import Config\n",
    "from dataset import RT_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/annotations_v2/train_total.csv')\n",
    "\n",
    "image_dir='/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/data_contrast/before/Image'\n",
    "\n",
    "train_dataset=RT_Dataset(train_df,image_dir,transforms=T.Compose([Augmenter(),Normalizer(),Resizer()]))\n",
    "    \n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = Config['TRAIN_BS'],\n",
    "    shuffle = True,\n",
    "    num_workers = Config['NUM_WORKERS'],\n",
    "    collate_fn = collater\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img': tensor([[[-1.9556, -1.8698, -1.6393],\n",
      "         [-1.9681, -1.8825, -1.6520],\n",
      "         [-1.9935, -1.9085, -1.6778],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.9710, -1.8855, -1.6549],\n",
      "         [-1.9911, -1.9061, -1.6754],\n",
      "         [-2.0110, -1.9265, -1.6957],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.9907, -1.9057, -1.6750],\n",
      "         [-1.9990, -1.9141, -1.6834],\n",
      "         [-2.0153, -1.9308, -1.7000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]]), 'annot': tensor([[247.7385,  70.6281, 508.4362,  92.0110,   2.0000],\n",
      "        [180.3501,  71.9241, 248.1704,  84.8834,   2.0000],\n",
      "        [659.8439,  86.3953, 667.1875,  90.9310,   1.0000],\n",
      "        [522.0435,  88.5552, 530.8990,  94.8188,   1.0000],\n",
      "        [513.1879,  93.9549, 519.4516,  99.5706,   1.0000]],\n",
      "       dtype=torch.float64), 'scale': 0.21598818814596077}\n",
      "{'img': tensor([[[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]]]), 'annot': tensor([[792.5249, 107.1706, 830.1522, 118.9291,   2.0000],\n",
      "        [654.1102, 108.8504, 748.8504, 124.3045,   2.0000],\n",
      "        [392.7349, 108.1785, 563.4016, 127.6640,   2.0000],\n",
      "        [292.9554, 105.8268, 379.9685, 122.6247,   2.0000]],\n",
      "       dtype=torch.float64), 'scale': 0.3359580052493438}\n",
      "{'img': tensor([[[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         [2.2489, 2.4286, 2.6400],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]]]), 'annot': tensor([[0.0000, 0.0000, 0.2000, 0.2000, 3.0000]], dtype=torch.float64), 'scale': 0.19996094512790472}\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficientdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import pandas as pd\n",
    "sys.path.append('/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/efficientdet_')\n",
    "import numpy as np\n",
    "from dataset import new_RT_dataset\n",
    "from config import Config\n",
    "from transform import *\n",
    "\n",
    "train_ann=pd.read_csv('/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/annotations_v2/train_total.csv')\n",
    "    \n",
    "\n",
    "image_dir='/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/data_contrast/before/Image'\n",
    "   \n",
    "train_dataset=new_RT_dataset(train_ann,image_dir,get_train_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    image,targets=train_dataset[i]\n",
    "    print(type(targets['boxes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids=train_ann['image_number'].unique()\n",
    "image_id=image_ids[12]\n",
    "records=train_ann[train_ann['image_number']==image_id]\n",
    "image=cv2.imread(f'{image_dir}/{records[\"dataset\"].values[0]}/{records[\"image_name\"].values[0]}',cv2.IMREAD_COLOR)\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "image /=255.0\n",
    "\n",
    "boxes=list(eval(records['bndbox'].iloc[0]))\n",
    "labels=list(eval(records['labels'].iloc[0]))\n",
    "\n",
    "target={}\n",
    "target['boxes']=boxes\n",
    "target['labels']=labels\n",
    "target['image_id']=image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixt",
   "language": "python",
   "name": "pixt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
