
Epoch: [0]  [  0/455]  eta: 0:22:35  lr: 0.000001  loss: 5.5083 (5.5083)  loss_classifier: 2.1070 (2.1070)  loss_box_reg: 0.0205 (0.0205)  loss_objectness: 3.1532 (3.1532)  loss_rpn_box_reg: 0.2276 (0.2276)  time: 2.9797  data: 0.4911  max mem: 2896
Epoch: [0]  [ 10/455]  eta: 0:04:45  lr: 0.000005  loss: 5.4172 (4.9826)  loss_classifier: 2.1255 (2.1227)  loss_box_reg: 0.0211 (0.0267)  loss_objectness: 3.1243 (2.6117)  loss_rpn_box_reg: 0.1993 (0.2214)  time: 0.6426  data: 0.0589  max mem: 3643
Epoch: [0]  [ 20/455]  eta: 0:03:54  lr: 0.000009  loss: 4.3158 (4.7498)  loss_classifier: 2.0377 (2.0058)  loss_box_reg: 0.0211 (0.0229)  loss_objectness: 2.0519 (2.5198)  loss_rpn_box_reg: 0.1328 (0.2013)  time: 0.4179  data: 0.0168  max mem: 3643
Epoch: [0]  [ 30/455]  eta: 0:03:39  lr: 0.000014  loss: 4.0036 (4.4059)  loss_classifier: 1.6439 (1.8128)  loss_box_reg: 0.0230 (0.0281)  loss_objectness: 2.0242 (2.3570)  loss_rpn_box_reg: 0.1377 (0.2081)  time: 0.4476  data: 0.0175  max mem: 3797
Epoch: [0]  [ 40/455]  eta: 0:03:25  lr: 0.000018  loss: 2.8412 (3.9973)  loss_classifier: 1.0961 (1.5983)  loss_box_reg: 0.0353 (0.0314)  loss_objectness: 1.6566 (2.1434)  loss_rpn_box_reg: 0.2043 (0.2242)  time: 0.4499  data: 0.0172  max mem: 3797
Epoch: [0]  [ 50/455]  eta: 0:03:15  lr: 0.000023  loss: 2.0278 (3.5288)  loss_classifier: 0.7403 (1.4085)  loss_box_reg: 0.0385 (0.0348)  loss_objectness: 0.9532 (1.8620)  loss_rpn_box_reg: 0.2043 (0.2235)  time: 0.4316  data: 0.0166  max mem: 3797
Epoch: [0]  [ 60/455]  eta: 0:03:08  lr: 0.000027  loss: 0.8626 (3.0869)  loss_classifier: 0.5188 (1.2491)  loss_box_reg: 0.0385 (0.0352)  loss_objectness: 0.1818 (1.5915)  loss_rpn_box_reg: 0.0799 (0.2112)  time: 0.4358  data: 0.0165  max mem: 3797
Epoch: [0]  [ 70/455]  eta: 0:02:57  lr: 0.000031  loss: 0.6941 (2.7660)  loss_classifier: 0.3655 (1.1129)  loss_box_reg: 0.0430 (0.0371)  loss_objectness: 0.1493 (1.3972)  loss_rpn_box_reg: 0.1379 (0.2187)  time: 0.4073  data: 0.0180  max mem: 3797
Epoch: [0]  [ 80/455]  eta: 0:02:51  lr: 0.000036  loss: 0.5875 (2.4944)  loss_classifier: 0.2060 (0.9950)  loss_box_reg: 0.0353 (0.0367)  loss_objectness: 0.1253 (1.2500)  loss_rpn_box_reg: 0.1515 (0.2127)  time: 0.3956  data: 0.0188  max mem: 3797
Epoch: [0]  [ 90/455]  eta: 0:02:45  lr: 0.000040  loss: 0.4620 (2.2770)  loss_classifier: 0.1187 (0.8966)  loss_box_reg: 0.0217 (0.0354)  loss_objectness: 0.1121 (1.1336)  loss_rpn_box_reg: 0.1711 (0.2113)  time: 0.4284  data: 0.0185  max mem: 3797
Epoch: [0]  [100/455]  eta: 0:02:39  lr: 0.000045  loss: 0.4323 (2.0983)  loss_classifier: 0.0924 (0.8176)  loss_box_reg: 0.0249 (0.0362)  loss_objectness: 0.1163 (1.0373)  loss_rpn_box_reg: 0.1780 (0.2073)  time: 0.4267  data: 0.0181  max mem: 3797
Epoch: [0]  [110/455]  eta: 0:02:34  lr: 0.000049  loss: 0.4720 (1.9542)  loss_classifier: 0.0744 (0.7526)  loss_box_reg: 0.0289 (0.0374)  loss_objectness: 0.1303 (0.9570)  loss_rpn_box_reg: 0.1656 (0.2072)  time: 0.4211  data: 0.0180  max mem: 3797
Epoch: [0]  [120/455]  eta: 0:02:30  lr: 0.000053  loss: 0.4720 (1.8351)  loss_classifier: 0.0893 (0.6984)  loss_box_reg: 0.0435 (0.0384)  loss_objectness: 0.1236 (0.8899)  loss_rpn_box_reg: 0.1708 (0.2084)  time: 0.4440  data: 0.0187  max mem: 3797
Epoch: [0]  [130/455]  eta: 0:02:27  lr: 0.000058  loss: 0.3351 (1.7193)  loss_classifier: 0.0893 (0.6521)  loss_box_reg: 0.0457 (0.0391)  loss_objectness: 0.0924 (0.8276)  loss_rpn_box_reg: 0.1275 (0.2005)  time: 0.4843  data: 0.0190  max mem: 3817
Epoch: [0]  [140/455]  eta: 0:02:22  lr: 0.000062  loss: 0.3200 (1.6350)  loss_classifier: 0.0736 (0.6118)  loss_box_reg: 0.0398 (0.0397)  loss_objectness: 0.0783 (0.7807)  loss_rpn_box_reg: 0.1173 (0.2029)  time: 0.4740  data: 0.0189  max mem: 3817
Epoch: [0]  [150/455]  eta: 0:02:17  lr: 0.000067  loss: 0.3310 (1.5507)  loss_classifier: 0.0736 (0.5768)  loss_box_reg: 0.0386 (0.0399)  loss_objectness: 0.0783 (0.7354)  loss_rpn_box_reg: 0.1393 (0.1986)  time: 0.4399  data: 0.0191  max mem: 3817
Epoch: [0]  [160/455]  eta: 0:02:13  lr: 0.000071  loss: 0.3920 (1.4813)  loss_classifier: 0.0656 (0.5470)  loss_box_reg: 0.0326 (0.0408)  loss_objectness: 0.0768 (0.6964)  loss_rpn_box_reg: 0.1165 (0.1972)  time: 0.4496  data: 0.0183  max mem: 3817
Epoch: [0]  [170/455]  eta: 0:02:09  lr: 0.000075  loss: 0.4248 (1.4155)  loss_classifier: 0.0832 (0.5208)  loss_box_reg: 0.0457 (0.0419)  loss_objectness: 0.0818 (0.6607)  loss_rpn_box_reg: 0.1150 (0.1922)  time: 0.4601  data: 0.0175  max mem: 3817
Epoch: [0]  [180/455]  eta: 0:02:04  lr: 0.000080  loss: 0.3263 (1.3580)  loss_classifier: 0.0832 (0.4964)  loss_box_reg: 0.0457 (0.0419)  loss_objectness: 0.0741 (0.6297)  loss_rpn_box_reg: 0.0977 (0.1901)  time: 0.4384  data: 0.0187  max mem: 3817
Epoch: [0]  [190/455]  eta: 0:01:59  lr: 0.000084  loss: 0.3467 (1.3078)  loss_classifier: 0.0888 (0.4755)  loss_box_reg: 0.0489 (0.0426)  loss_objectness: 0.0740 (0.6018)  loss_rpn_box_reg: 0.1258 (0.1879)  time: 0.4149  data: 0.0187  max mem: 3817
Traceback (most recent call last):
  File "/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/faster-rcnn/train.py", line 86, in <module>
    train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=10)
  File "/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/faster-rcnn/engine.py", line 26, in train_one_epoch
    for images, targets in metric_logger.log_every(data_loader, print_freq, header):
  File "/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/faster-rcnn/utils.py", line 201, in log_every
    for obj in iterable:
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/irteam/junghye-dcloud-dir/pathfinder/pathfinder_ai/faster-rcnn/dataset.py", line 61, in __getitem__
    sample=self.transforms(image=image_res,
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/composition.py", line 207, in __call__
    p.preprocess(data)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/utils.py", line 83, in preprocess
    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction="to")
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/utils.py", line 91, in check_and_convert
    return self.convert_to_albumentations(data, rows, cols)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/bbox_utils.py", line 142, in convert_to_albumentations
    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/bbox_utils.py", line 408, in convert_bboxes_to_albumentations
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/bbox_utils.py", line 408, in <listcomp>
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/bbox_utils.py", line 352, in convert_bbox_to_albumentations
    check_bbox(bbox)
  File "/home/irteam/anaconda3/envs/pixt/lib/python3.10/site-packages/albumentations/core/bbox_utils.py", line 435, in check_bbox
    raise ValueError(f"Expected {name} for bbox {bbox} to be in the range [0.0, 1.0], got {value}.")
ValueError: Expected y_max for bbox (tensor(0.6238), tensor(0.9011), tensor(0.6598), tensor(1.0045), tensor(3)) to be in the range [0.0, 1.0], got 1.0044944286346436.